import numpy as np
import torch.nn as nn
from kaggle_utils.loader_utils import preprocess_data
from kaggle_utils.training_utils import split_and_train, predict_test_data
from kaggle_utils.plot_utils import plot_losses
from kaggle_utils.models.multi_class.MultiClassNN import MultiClassNN
from kaggle_utils.models.model_utils import get_model_summary

TRAINING_CSV_PATH = "train.csv"
TESTING_CSV_PATH = "test.csv"
FEATURE_CONFIG_PATH = "feature_config.json"
LABEL_COLUMN = 'Survived'
ID_COLUMN = 'PassengerId'
EXCLUDED_FIELDS = ["Name", "Ticket", "Cabin"]
NUM_EPOCHS = 200


training_df = preprocess_data(TRAINING_CSV_PATH,
                              FEATURE_CONFIG_PATH,
                              EXCLUDED_FIELDS)
X = training_df.drop(LABEL_COLUMN, axis=1).astype(np.float32)
y = training_df[LABEL_COLUMN].astype(np.float32).squeeze()
X


# Train with NN
criterion = nn.CrossEntropyLoss()
input_size = X.shape[1]
nn_model = MultiClassNN(input_size,
                        layer_sizes=[512, 256, 128, 64, 32, 16],
                        num_classes=2)
nn_model, train_losses, val_losses = split_and_train(X, y,
                                                     nn_model, NUM_EPOCHS,
                                                     criterion, lr=0.00001)
plot_losses(train_losses, val_losses)


get_model_summary(nn_model, input_shape=X.shape)


testing_df = preprocess_data(TESTING_CSV_PATH,
                             FEATURE_CONFIG_PATH,
                             EXCLUDED_FIELDS + [LABEL_COLUMN]).astype(np.float32)
submission = predict_test_data(nn_model, testing_df, ID_COLUMN, LABEL_COLUMN)
submission.to_csv('titanic/titanic_predictions.csv', index=False)



